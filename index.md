
<div align=center>
<img src="/assets/img/lihu_avatar.jpeg" width="200px" />
</div>

<br>

[![GitHub](https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white)](https://github.com/tigerchen52) 
[![Scholar](https://img.shields.io/badge/Google-4285F4?logo=google&logoColor=white)](https://scholar.google.com/citations?user=oRs8regAAAAJ&hl=en)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000)](https://huggingface.co/Lihuchen)
[![LinkedIn](https://img.shields.io/badge/Linkedin-%230077B5.svg?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/lihu-chen-43482a284/)
[![X](https://img.shields.io/badge/X-%23000000.svg?logo=X&logoColor=white)](https://twitter.com/LihuChen)


___

ðŸ“¢ðŸ“¢ **News**
* Our Pub-Guard-LLM is hosted on ðŸ¤— [HuggingFace](https://huggingface.co/Lihuchen/pub-guard-llama-8b), the first LLM-based system to detect fraudulent articles in the biomedical field. <a href="https://arxiv.org/pdf/2502.15429">
  <img src="https://img.shields.io/badge/PDF-arxiv-10868" alt="PDF Badge" width="50" height="13">
 </a> <a href="https://github.com/tigerchen52/pub_guard_llm">
  <img src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white" alt="PDF Badge" width="50" height="13"></a>  <br>
* Our QR-Neuron is accepted at AAAI 2025 as an oral presentation <a href="https://arxiv.org/abs/2406.10868">
  <img src="https://img.shields.io/badge/PDF-arxiv-10868" alt="PDF Badge" width="50" height="13">
 </a> <a href="https://github.com/tigerchen52/qrneuron">
  <img src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white" alt="PDF Badge" width="50" height="13"></a>  <br>
* One paper accepted by EMNLP 2024 Findings. "Reconfidencing LLMs from the Grouping Loss Perspective"  <a href="https://arxiv.org/pdf/2402.04957">
  <img src="https://img.shields.io/badge/PDF-arxiv-10868" alt="PDF Badge" width="50" height="13">
 </a> <br>
* Check out our survey about the role of small models in the LLM era <a href="https://arxiv.org/abs/2409.06857">
  <img src="https://img.shields.io/badge/PDF-arxiv-10868" alt="PDF Badge" width="50" height="13">
 </a> <a href="https://github.com/tigerchen52/role_of_small_models">
  <img src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white" alt="PDF Badge" width="50" height="13"></a> <br>
* Our new version of [YAGO knowledge base](https://yago-knowledge.org/) is available, which is accepted by SIGIR 2024 <a href="https://dl.acm.org/doi/abs/10.1145/3626772.3657876"> 
  <img src="https://img.shields.io/badge/PDF-SIGIR-10868" alt="PDF Badge" width="50" height="13">
 </a> <br>
* Our PEARL is available on ðŸ¤— [HuggingFace](https://huggingface.co/Lihuchen/pearl_small), a lightweight and powerful embedding model for short texts <a href="https://huggingface.co/Lihuchen/pearl_small"> 
  <img src="https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000" alt="PDF Badge" width="60" height="13">
 </a> <br>

___

My name is Lihu Chen (é™ˆç«‹è™Ž), and I am currently a Research Associate at [Imperial College London](https://www.imperial.ac.uk/). 
Before that, I did a one-year postdoc at [Inria Saclay](https://www.inria.fr/en/inria-saclay-centre). I obtained my PhD at [DIG](https://dig.telecom-paris.fr/blog/) team of [TÃ©lÃ©com Paris](https://www.telecom-paris.fr/en/home), which is a member of [Institut Polytechnique de Paris](https://www.ip-paris.fr/en). I was co-supervised by [Fabian Suchanek](https://suchanek.name/) and [GaÃ«l Varoquaux](http://gael-varoquaux.info/). <br>

My research primarily focuses on natural language processing (NLP) and large language models (LLMs).
I am dedicated to developing efficient, reliable, and open-source models and tools, with a particular emphasis on information extraction and biomedical applications. Specifically, my research topics include: 

* **Large vs Small: Collaborative AI Modeling Approaches**.  In our [survey](https://arxiv.org/abs/2409.06857), we systematically examine the collaborations between LLMs and SMs.
My research will primarily build upon this foundational concept, focusing on leveraging the complementary strengths of both LLMs and SMs. 
* **Interpretable and Trustworthy Models**. The goal of interpretability is to provide a human-understandable explanation of a modelâ€™s internal reasoning process, i.e., *how the model works (transparency)*. I am interested in uncertainty estimation, knowledge mechanism of LLMs, and fact-checking.
* **Efficient Knowledge-Augmented LLMs**. LLMs may struggle with tasks that require domain-specific expertise or up-to-date information. I aim to explore cost-effective methods for enhancing reasoning capabilities, e.g. logical reasoning. 
* **Long-term Research Question: Can AI Think Like Humans**: New Architectures? Multimodality? New Learning Objectives? Neuro-symbolic Integration? We'll see!


___


### Misc
* My [Github](https://github.com/tigerchen52) 
* Human Language: Chinese Mandarin (Native); English (Fluent); French (Basic)
* [Travel Photos](https://chenlihu.com/blog/)

___

### Contact
**Email**:[firstname].[lastname][AT]imperial.ac.uk

I am open to discussions and collaborations. Feel free to reach out!
